{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Aula 03** - Processamento de Texto e Pré-processamento de Dados"
      ],
      "metadata": {
        "id": "T5dkw3AClodw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O pré-processamento limpa e transforma esse texto para facilitar o trabalho do algoritmo, deixando só as informações relevantes. Técnicas de Pré-processamento de Texto:\n",
        "\n",
        "1. **Normalização de Texto** - Ajuste do texto para ter uma grafia padronizada;\n",
        "2. **Remoção de Ruido** - Retirar elementos do texto que não agregam valor à análise e podem atrapalhar;\n",
        "3. **Tokenização** - Tokenizar é dividir o texto em pequenas unidade;\n",
        "4. **Remoção de Stopwords** - Remover palavras que não carregam muito significado para análise;\n",
        "5. **Stemming** - Técnica para reduzir palavras às suas raizes ou radicais, cortando sufixos e prefixos;\n",
        "6. **Lematização** - Redução da palavra para a sua forma de dicionário (forma canônica)."
      ],
      "metadata": {
        "id": "9_EBpm9Bl0TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Normalização de texto e Remoção de Ruido"
      ],
      "metadata": {
        "id": "nQsZsmk5sbLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Remover caracteres especiais, pontuações, e normalizar o uso de letras maiúsculas e minúsculas"
      ],
      "metadata": {
        "id": "iAEgn3D7sol7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importa a biblioteca para trabalhar com expressões regulares\n",
        "import re\n",
        "\n",
        "original = \"Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e LETRAS maiúsculas.\"\n",
        "\n",
        "texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]', '',original)\n",
        "  # re.sub() função que realiza substituição\n",
        "  # r'[^A-Za-zÀ-ÿ\\s]'>>> expressão regular que define um conjunto de caracteres a serem removidos\n",
        "    # [A-Za-zÀ-ÿ\\s] >>> define um conjunto de caracteres de A até Z, a até z e acentos e espaços\n",
        "    # ^faz a negação de uma expressão regular\n",
        "  # '' substitui a expressão regular por uma string vazia\n",
        "\n",
        "texto_normalizado = texto_limpo.lower()\n",
        "\n",
        "print(f'Texto original: {original}')\n",
        "print(f'\\nTexto limpo: {texto_limpo}')\n",
        "print(f'\\nTexto normalizado: {texto_normalizado}')"
      ],
      "metadata": {
        "id": "MLcaRgmBtUSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e4cbf5-00b8-4877-a5d5-e54255cd8900"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e LETRAS maiúsculas.\n",
            "\n",
            "Texto limpo: Olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e LETRAS maiúsculas\n",
            "\n",
            "Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Tokenização"
      ],
      "metadata": {
        "id": "zPHxZp3XtWRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Tokenização é dividir o texto em unidades menores (tokens), que geralmente são palavras"
      ],
      "metadata": {
        "id": "bVCrmZVDxPzS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vxsds8nIe2rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a14a55-bd45-48e4-b4b8-9c5a79012e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e LETRAS maiúsculas.\n",
            "\n",
            "\n",
            "Texto limpo: Olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e LETRAS maiúsculas\n",
            "\n",
            "\n",
            "Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n",
            "\n",
            "\n",
            "Tokens extraidos: ['olá', 'este', 'é', 'um', 'exemplo', 'de', 'texto', 'com', 'várias', 'pontuações', 'símbolos', 'especiais', 'e', 'letras', 'maiúsculas']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "tokens = word_tokenize(texto_normalizado)\n",
        "\n",
        "print(f'Texto original: {original}')\n",
        "print(f'\\n\\nTexto limpo: {texto_limpo}')\n",
        "print(f'\\n\\nTexto normalizado: {texto_normalizado}')\n",
        "print(f'\\n\\nTokens extraidos: {tokens}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Remoção de Stopwords"
      ],
      "metadata": {
        "id": "X0YPELSUxjL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Stopwords são palavras de pouco valor semântico (como \"de\", \"a\", \"o\") que podem ser removidas para simplificar o texto"
      ],
      "metadata": {
        "id": "hDAJIcohxnOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "print(stopwords_pt)\n",
        "\n",
        "tokens_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n",
        "\n",
        "print(f'\\n\\nTokens extraidos: {tokens} + \\n quantidade de tokens: {len(tokens)}')\n",
        "print(f'\\n\\nTokens extraidos: {tokens_sem_stopwords} + \\n quantidade de tokens: {len(tokens_sem_stopwords)}\\n')"
      ],
      "metadata": {
        "id": "MPCy16XexyWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0676d7ce-e6e6-466d-8a69-627b706b30e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mais', 'teremos', 'dos', 'houve', 'esta', 'tivesse', 'e', 'tinham', 'aqueles', 'fôssemos', 'era', 'por', 'tivermos', 'me', 'lhe', 'nem', 'entre', 'seus', 'tenham', 'numa', 'tem', 'uma', 'houveriam', 'teu', 'minhas', 'havemos', 'será', 'fomos', 'sejamos', 'estou', 'teriam', 'estava', 'haver', 'ela', 'que', 'seu', 'estiver', 'tivessem', 'estejam', 'está', 'somos', 'quando', 'nossas', 'fôramos', 'tuas', 'fossem', 'estes', 'houveremos', 'tinha', 'serei', 'aquilo', 'houvesse', 'um', 'vos', 'estávamos', 'se', 'pela', 'da', 'éramos', 'estivéramos', 'as', 'seria', 'tém', 'deles', 'nossa', 'houveríamos', 'de', 'pelas', 'estamos', 'meu', 'são', 'terão', 'aos', 'do', 'esteve', 'hão', 'haja', 'estive', 'você', 'estivesse', 'a', 'esses', 'dele', 'essas', 'só', 'foram', 'eu', 'para', 'tivéramos', 'sem', 'estar', 'tua', 'à', 'teríamos', 'pelo', 'este', 'for', 'houveria', 'estivéssemos', 'tenhamos', 'fui', 'num', 'vocês', 'houvermos', 'ou', 'tivéssemos', 'houveram', 'mesmo', 'elas', 'depois', 'esteja', 'eram', 'teus', 'fora', 'hajam', 'estivermos', 'isso', 'tenha', 'tivemos', 'serão', 'até', 'sua', 'pelos', 'não', 'formos', 'houverá', 'estivera', 'nas', 'ser', 'houvéramos', 'muito', 'em', 'seremos', 'tivera', 'aquele', 'tínhamos', 'suas', 'estejamos', 'estas', 'seriam', 'houverei', 'estão', 'aquelas', 'sou', 'no', 'tu', 'estivessem', 'mas', 'houvéssemos', 'o', 'na', 'qual', 'minha', 'seja', 'tiveram', 'sejam', 'houvessem', 'há', 'eles', 'temos', 'houvera', 'quem', 'tenho', 'já', 'ao', 'terá', 'houvemos', 'isto', 'estiverem', 'estiveram', 'como', 'hajamos', 'nós', 'aquela', 'houver', 'também', 'terei', 'teria', 'fosse', 'houverão', 'nos', 'houverem', 'nossos', 'com', 'meus', 'lhes', 'delas', 'estavam', 'ele', 'estivemos', 'te', 'tiver', 'foi', 'é', 'teve', 'às', 'tiverem', 'seríamos', 'essa', 'nosso', 'hei', 'das', 'forem', 'os', 'dela', 'esse', 'tive'}\n",
            "\n",
            "\n",
            "Tokens extraidos: ['olá', 'este', 'é', 'um', 'exemplo', 'de', 'texto', 'com', 'várias', 'pontuações', 'símbolos', 'especiais', 'e', 'letras', 'maiúsculas'] + \n",
            " quantidade de tokens: 15\n",
            "\n",
            "\n",
            "Tokens extraidos: ['olá', 'exemplo', 'texto', 'várias', 'pontuações', 'símbolos', 'especiais', 'letras', 'maiúsculas'] + \n",
            " quantidade de tokens: 9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Stemming e Lemalização"
      ],
      "metadata": {
        "id": "ze4bxKBfx7WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Stemming reduz as palavras às suas raízes (ou radicais);\n",
        "*   Lematização normaliza as palavras para suas formas base, levando em conta contexto e gramática."
      ],
      "metadata": {
        "id": "Iwn1attYx8mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download('rslp')\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "stemming = [stemmer.stem(palavra) for palavra in tokens_sem_stopwords]\n",
        "print(f'\\n\\nTokens extraidos: {tokens_sem_stopwords}')\n",
        "print(f'\\n\\nTokens radicais: {stemming}\\n\\n\\n')"
      ],
      "metadata": {
        "id": "fAFQyx0gx_SZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3857c579-1d1c-4eae-c758-40eacef6b711"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tokens extraidos: ['olá', 'exemplo', 'texto', 'várias', 'pontuações', 'símbolos', 'especiais', 'letras', 'maiúsculas']\n",
            "\n",
            "\n",
            "Tokens radicais: ['olá', 'exempl', 'text', 'vár', 'pontu', 'símbol', 'espec', 'letr', 'maiúscul']\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Exemplo 01 - Pré Processamento completo"
      ],
      "metadata": {
        "id": "9cKBfNLJyhzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "# Download dos recursos do NLTK (se necessário)\n",
        "#nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = input(\"Insira um texto que seja coerente, podendo ter símbolos: \")\n",
        "\n",
        "# Limpeza de ruídos e normalização\n",
        "texto_limpo = re.sub(r'[^a-zA-Z]', ' ', texto)  # Remove tudo que não for letra e substitui por espaço\n",
        "texto_lower = texto_limpo.lower()  # Converte para minúsculas\n",
        "\n",
        "# Tokenização\n",
        "tokens = nltk.word_tokenize(texto_lower)\n",
        "\n",
        "# Remoção de stopwords\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "palavras_filtradas = [palavra for palavra in tokens if palavra not in stop_words]\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras_filtradas]\n",
        "\n",
        "# Impressão do resultado final\n",
        "print(palavras_stemizadas)"
      ],
      "metadata": {
        "id": "8zBXUooxyi_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88aeab6-ef2e-4f08-e009-776fd75fd207"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insira um texto que seja coerente, podendo ter símbolos: A vida é uma lição e temos que aprender. Para nos ensinar, Deus usa a vida e a vida usa tudo.\n",
            "['vida', 'li', 'aprend', 'ensinar', 'deu', 'usa', 'vida', 'vida', 'usa', 'tudo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 02 - Estrutura de Pré-processamento de texto"
      ],
      "metadata": {
        "id": "530IRn23yl7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "A1BG21ceyqJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3106283a-54d8-46d0-ac91-3aa45091915c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "\n",
        "# Baixar stopwords do NLTK (se necessário)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('rslp')\n",
        "\n",
        "# Carregar modelo do spaCy (português como exemplo, pode trocar para 'en_core_web_sm' se for inglês)\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Texto de exemplo (pode ser uma review ou trecho de notícia)\n",
        "texto = \"O Processamento de Linguagem Natural (PLN) é uma área essencial da inteligência artificial! 😊 Confira mais em: https://exemplo.com\"\n",
        "\n",
        "# 1. Normalização (remover acentos, transformar em minúsculas, etc.)\n",
        "def normalizar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'https?://\\S+|www\\.\\S+', '', texto)  # Remover URLs\n",
        "    texto = re.sub(r'[^a-zA-Zá-úÁ-ÚçÇ ]', '', texto)     # Remover caracteres especiais (ajuste para outros idiomas)\n",
        "    return texto\n",
        "\n",
        "texto_normalizado = normalizar_texto(texto)\n",
        "\n",
        "# 2. Tokenização (nltk)\n",
        "tokens = nltk.word_tokenize(texto_normalizado, language='portuguese')\n",
        "\n",
        "# 3. Remoção de stopwords (nltk)\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "tokens_sem_stopwords = [token for token in tokens if token not in stopwords_pt]\n",
        "\n",
        "# 4. Stemming (nltk)\n",
        "stemmer = nltk.RSLPStemmer()\n",
        "tokens_stem = [stemmer.stem(token) for token in tokens_sem_stopwords]\n",
        "\n",
        "# 5. Lematização (spaCy)\n",
        "def lematizar_com_spacy(tokens):\n",
        "    doc = nlp(\" \".join(tokens))\n",
        "    return [token.lemma_ for token in doc]\n",
        "\n",
        "tokens_lematizados = lematizar_com_spacy(tokens_sem_stopwords)\n",
        "\n",
        "# 6. Comparação\n",
        "print(\"Texto Original:\\n\", texto)\n",
        "print(\"\\nTexto Normalizado:\\n\", texto_normalizado)\n",
        "print(\"\\nTokens:\\n\", tokens)\n",
        "print(\"\\nTokens Sem Stopwords:\\n\", tokens_sem_stopwords)\n",
        "print(\"\\nStemming:\\n\", tokens_stem)\n",
        "print(\"\\nLematização:\\n\", tokens_lematizados)"
      ],
      "metadata": {
        "id": "wu3xzhZcyvOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae300c1-2a85-4911-8aad-56d45be48470"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto Original:\n",
            " O Processamento de Linguagem Natural (PLN) é uma área essencial da inteligência artificial! 😊 Confira mais em: https://exemplo.com\n",
            "\n",
            "Texto Normalizado:\n",
            " o processamento de linguagem natural pln é uma área essencial da inteligência artificial  confira mais em \n",
            "\n",
            "Tokens:\n",
            " ['o', 'processamento', 'de', 'linguagem', 'natural', 'pln', 'é', 'uma', 'área', 'essencial', 'da', 'inteligência', 'artificial', 'confira', 'mais', 'em']\n",
            "\n",
            "Tokens Sem Stopwords:\n",
            " ['processamento', 'linguagem', 'natural', 'pln', 'área', 'essencial', 'inteligência', 'artificial', 'confira']\n",
            "\n",
            "Stemming:\n",
            " ['process', 'lingu', 'natur', 'pln', 'áre', 'essenc', 'intelig', 'artific', 'conf']\n",
            "\n",
            "Lematização:\n",
            " ['processamento', 'linguagem', 'natural', 'pln', 'área', 'essencial', 'inteligência', 'artificial', 'confira']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 03 - O modelo pre treinado"
      ],
      "metadata": {
        "id": "Y0bvOD9Uy8Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Carregar o modelo para português\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Processar um texto em português\n",
        "textoRecebido = input(\"Digite um texto para ser analisado: \")\n",
        "doc = nlp(textoRecebido)\n",
        "\n",
        "print('\\nAnálise gramatical das palavras:')\n",
        "for token in doc:\n",
        "    print(f\"Palavra: {token.text}, Classe: {token.pos_}\")\n",
        "\n",
        "print(\"\\nAnalise de Dependências:\")\n",
        "for token in doc:\n",
        "  print(f\"Palavra: {token.text}, Depende de: {token.head.text}\")\n",
        "\n",
        "# Visualizar a árvore graficamente (opcional)\n",
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "id": "P_cj5JK9zGQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25300be7-09c0-477f-d4fa-d78b6b68cbac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite um texto para ser analisado: A vida é uma lição e temos que aprender. Para nos ensinar, Deus usa a vida e a vida usa tudo.\n",
            "\n",
            "Análise gramatical das palavras:\n",
            "Palavra: A, Classe: DET\n",
            "Palavra: vida, Classe: NOUN\n",
            "Palavra: é, Classe: AUX\n",
            "Palavra: uma, Classe: DET\n",
            "Palavra: lição, Classe: NOUN\n",
            "Palavra: e, Classe: CCONJ\n",
            "Palavra: temos, Classe: VERB\n",
            "Palavra: que, Classe: SCONJ\n",
            "Palavra: aprender, Classe: VERB\n",
            "Palavra: ., Classe: PUNCT\n",
            "Palavra: Para, Classe: SCONJ\n",
            "Palavra: nos, Classe: PRON\n",
            "Palavra: ensinar, Classe: VERB\n",
            "Palavra: ,, Classe: PUNCT\n",
            "Palavra: Deus, Classe: PROPN\n",
            "Palavra: usa, Classe: VERB\n",
            "Palavra: a, Classe: DET\n",
            "Palavra: vida, Classe: NOUN\n",
            "Palavra: e, Classe: CCONJ\n",
            "Palavra: a, Classe: DET\n",
            "Palavra: vida, Classe: NOUN\n",
            "Palavra: usa, Classe: VERB\n",
            "Palavra: tudo, Classe: PRON\n",
            "Palavra: ., Classe: PUNCT\n",
            "\n",
            "Analise de Dependências:\n",
            "Palavra: A, Depende de: vida\n",
            "Palavra: vida, Depende de: lição\n",
            "Palavra: é, Depende de: lição\n",
            "Palavra: uma, Depende de: lição\n",
            "Palavra: lição, Depende de: lição\n",
            "Palavra: e, Depende de: temos\n",
            "Palavra: temos, Depende de: aprender\n",
            "Palavra: que, Depende de: aprender\n",
            "Palavra: aprender, Depende de: lição\n",
            "Palavra: ., Depende de: lição\n",
            "Palavra: Para, Depende de: ensinar\n",
            "Palavra: nos, Depende de: ensinar\n",
            "Palavra: ensinar, Depende de: usa\n",
            "Palavra: ,, Depende de: ensinar\n",
            "Palavra: Deus, Depende de: usa\n",
            "Palavra: usa, Depende de: usa\n",
            "Palavra: a, Depende de: vida\n",
            "Palavra: vida, Depende de: usa\n",
            "Palavra: e, Depende de: usa\n",
            "Palavra: a, Depende de: vida\n",
            "Palavra: vida, Depende de: usa\n",
            "Palavra: usa, Depende de: usa\n",
            "Palavra: tudo, Depende de: usa\n",
            "Palavra: ., Depende de: usa\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"754a7e16ea7c41deadd858cd0d60141e-0\" class=\"displacy\" width=\"3725\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">A</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">vida</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">é</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">uma</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">lição</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">e</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">temos</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">que</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">aprender.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Para</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">nos</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">ensinar,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">Deus</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">usa</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">vida</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">e</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">vida</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">usa</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">tudo.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-7\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,89.5 2320.0,89.5 2320.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,266.5 L1987,254.5 2003,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-11\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,266.5 L2162,254.5 2178,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-12\" stroke-width=\"2px\" d=\"M2520,264.5 C2520,177.0 2665.0,177.0 2665.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,266.5 L2512,254.5 2528,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-13\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,89.5 2670.0,89.5 2670.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2670.0,266.5 L2678.0,254.5 2662.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-14\" stroke-width=\"2px\" d=\"M2870,264.5 C2870,89.5 3370.0,89.5 3370.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,266.5 L2862,254.5 2878,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-15\" stroke-width=\"2px\" d=\"M3045,264.5 C3045,177.0 3190.0,177.0 3190.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,266.5 L3037,254.5 3053,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-16\" stroke-width=\"2px\" d=\"M3220,264.5 C3220,177.0 3365.0,177.0 3365.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,266.5 L3212,254.5 3228,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-17\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,2.0 3375.0,2.0 3375.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3375.0,266.5 L3383.0,254.5 3367.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-754a7e16ea7c41deadd858cd0d60141e-0-18\" stroke-width=\"2px\" d=\"M3395,264.5 C3395,177.0 3540.0,177.0 3540.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-754a7e16ea7c41deadd858cd0d60141e-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3540.0,266.5 L3548.0,254.5 3532.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O que são: Conjuntos de dados estatísticos e regras, Treinados com milhões de textos, Especializados em tarefas específicas de linguagem, Resultado de aprendizado de máquina\n",
        "* Como são treinados: Alimentados com grande volume de textos, Aprendem padrões do idioma, Reconhecem estruturas gramaticais, Identificam relações entre palavras, São testados e refinados\n",
        "* Tipos de modelos por tamanho:\n",
        "  * Pequeno (sm): Mais rápido, menor precisão, Usa menos memória, Bom para testes\n",
        "  * Médio (md): Equilíbrio entre velocidade e precisão, Precisão moderada\n",
        "Bom para uso geral\n",
        "  * Grande (lg): Mais preciso, Mais lento, Usa mais memória, Melhor para análises detalhadas\n",
        "* Alguns modelos pré-treinados:\n",
        "  * Português - nlp_pt = spacy.load('pt_core_news_sm')\n",
        "  * Inglês - nlp_en = spacy.load('en_core_web_sm')\n",
        "  * Espanhol - nlp_es = spacy.load('es_core_news_sm')\n",
        "  * Francês - nlp_fr = spacy.load('fr_core_news_sm')\n",
        "  * Alemão - nlp_de = spacy.load('de_core_news_sm')"
      ],
      "metadata": {
        "id": "dUcm9tmkzPXg"
      }
    }
  ]
}