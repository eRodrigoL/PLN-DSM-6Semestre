{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 06 - Interpretação Semântica e Gramática"
      ],
      "metadata": {
        "id": "HueIoTHKruDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Compreender os conceitos de **interpretação semântica** e sua impotância no Processsamento de Linguagem Natural (PLN).\n",
        "* Explorar **estruturas gramaticais** e seu impacto na análise de textos.\n",
        "* Aplicar técnicas de **análise semântica** em um corpus textual.\n",
        "* Utilizar bibliotecas de PLN para **extrair significado de textos**."
      ],
      "metadata": {
        "id": "Lkb4oE4ZsW0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01 - Representação do significado das palavras e frases com redes Semânticas."
      ],
      "metadata": {
        "id": "HSKlxZVw3EMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhDW183d1Eml",
        "outputId": "f4b310c6-51dd-417e-b94a-8e694745bb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('beach_wagon.n.01'), Synset('car.n.01'), Synset('car.n.02'), Synset('cart.n.01')]\n",
            "beach_wagon\n",
            "car\n",
            "car\n",
            "cart\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "  # banco de dados para utilização dos sinônimos\n",
        "nltk.download('omw-1.4')\n",
        "  # Corpus que relaciona as palavras em diversos idiomas - tradução automática\n",
        "\n",
        "# Método para encontrar os sinônimos da palavra inidicada e o idioma\n",
        "sinonimos = wordnet.synsets(\"carro\", lang=\"por\")\n",
        "\n",
        "print (sinonimos) # imprime a lista gerada\n",
        "\n",
        "for s in sinonimos:\n",
        "  print(s.lemmas ()[0].name()) # Mostra sinônimos da palavra\n",
        "  # s.lammas(): Obtém a lista de lemmas (formas básicas das palavras) no synset atual.\n",
        "  # [0]: Pega o primeiro lemma da lista.\n",
        "  # .name(): Obtém o nome do lemma (o sinônimos em si)\n",
        "  # print(): Imprime o sinônio na tela"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 02 - Representação do significado das palavras e frases por Vetores (embeddings)."
      ],
      "metadata": {
        "id": "EfPp7XKv7KQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy\n",
        "# !python -m spacy download pt_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRdZUx0O7Vwo",
        "outputId": "812c97eb-dab1-46f0-ac51-595dd700b356"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0-py3-none-any.whl (42.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-md\n",
            "Successfully installed pt-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Carregando o modelo pre treinado - modelo com relações entre palavras\n",
        "\n",
        "nlp = spacy.load('pt_core_news_md')\n",
        "\n",
        "# criação de objetos, com suas informações e vetores\n",
        "palavral = nlp('rei')\n",
        "palavra2 = nlp('rainha')\n",
        "\n",
        "# Calculo de similaridade dos objetos vetorizadas\n",
        "print (palavral.similarity(palavra2))\n",
        "  # valor próximo de 1 = palavras similares (proximidade vetorial)\n",
        "  # valor próximo de -1 = palavras antonimas (distância vetorial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DabB_dto76VH",
        "outputId": "78d0b828-3145-4c98-8f6f-05a8e5625b17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6001228094100952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 03 - Árvore Sintática"
      ],
      "metadata": {
        "id": "yP3RqZdqBIvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lzc0V1KCZlL",
        "outputId": "7f9821a9-5d06-41ee-dab4-de9deebb64c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        " # módulo para visualização de dependências\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "frase = \"O cachorro correu no parque.\"\n",
        "doc = nlp (frase)\n",
        "\n",
        "displacy.render(doc, style= 'dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "LHpNU4YACHbf",
        "outputId": "8ef406ed-4dad-4a3a-d375-1464a9d361bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"845178d181b848a387ed933e8072a62c-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cachorro</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">correu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">parque.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-845178d181b848a387ed933e8072a62c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-845178d181b848a387ed933e8072a62c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-845178d181b848a387ed933e8072a62c-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-845178d181b848a387ed933e8072a62c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-845178d181b848a387ed933e8072a62c-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-845178d181b848a387ed933e8072a62c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-845178d181b848a387ed933e8072a62c-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-845178d181b848a387ed933e8072a62c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 04 - Ontologia"
      ],
      "metadata": {
        "id": "OSkz5-v1Cqat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install owlready2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooysdL_oCu6H",
        "outputId": "cbc59c77-081a-438a-d7d9-d460405cffe3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting owlready2\n",
            "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=24577502 sha256=dc17f0d6939994b81b8dc4df66f0e4c761839484ebd6e78c894b3cc7440ffdb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from owlready2 import *\n",
        "\n",
        "# Criando uma nova ontologia\n",
        "onto = get_ontology (\"http://exemplo.com/minha_ontologia.owl\")\n",
        "\n",
        "with onto:\n",
        "  class Animal (Thing): pass\n",
        "  class Mamifero (Animal): pass\n",
        "  class Cachorro (Mamifero): pass\n",
        "  class Gato (Mamifero): pass\n",
        "\n",
        "onto.save(\"minha_ontologia.owl\")"
      ],
      "metadata": {
        "id": "fUV0lJZSDTRZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estudo de Caso 01 - Aplicação de Análise Semântica em um corpus\n"
      ],
      "metadata": {
        "id": "kqdujQLWD_zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "  # banco de dados léxico - agrupa palavras em conjuntos de sinônimos\n",
        "\n",
        "# baixando os corpus e o modelo pré treinado\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "  # Acessar as funcionalidades como tokenização, análise sintática e vetores de pala"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn2idhhUEEgy",
        "outputId": "2534d7e1-8a8d-40b9-a96b-a22e8ea92517"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded apple in 1976.\"\n",
        "\n",
        "# 1. Análise Sintática\n",
        "doc = nlp(text)\n",
        "syntactic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  syntactic_data.append({\n",
        "      \"Token\": token.text,\n",
        "      \"Pos-Tag\": token.pos_,\n",
        "      \"Dependência\": token.dep_,\n",
        "      \"Cabeça de Dep\": token.head.text\n",
        "  })\n",
        "\n",
        "\n",
        "# Convertendo para DataFrame\n",
        "df_syntactic = pd.DataFrame(syntactic_data)\n",
        "print(\"\\n Análise Sintática:\")\n",
        "print(df_syntactic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVSgI4juE0yv",
        "outputId": "485c4855-230c-4bfe-8ccd-06ae1cd4092f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Análise Sintática:\n",
            "      Token Pos-Tag Dependência Cabeça de Dep\n",
            "0     Apple   PROPN       nsubj       looking\n",
            "1        is     AUX         aux       looking\n",
            "2   looking    VERB        ROOT       looking\n",
            "3        at     ADP        prep       looking\n",
            "4    buying    VERB       pcomp            at\n",
            "5      U.K.   PROPN       nsubj       startup\n",
            "6   startup    VERB       ccomp        buying\n",
            "7       for     ADP        prep       startup\n",
            "8         $     SYM    quantmod       billion\n",
            "9         1     NUM    compound       billion\n",
            "10  billion     NUM        pobj           for\n",
            "11        .   PUNCT       punct       looking\n",
            "12    Steve   PROPN    compound          Jobs\n",
            "13     Jobs   PROPN       nsubj       founded\n",
            "14  founded    VERB        ROOT       founded\n",
            "15    apple    NOUN        dobj       founded\n",
            "16       in     ADP        prep       founded\n",
            "17     1976     NUM        pobj            in\n",
            "18        .   PUNCT       punct       founded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "\n",
        "entities_data = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  entities_data.append({\n",
        "      \"Entidade\": ent.text,\n",
        "      \"Tipo\": ent.label_,\n",
        "  })\n",
        "\n",
        "# Convertendo para DataFrame\n",
        "df_entities = pd.DataFrame(entities_data)\n",
        "print(\"\\n Reconhecimento de Entidades:\")\n",
        "print(df_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpatOBZXH2ic",
        "outputId": "d63a3c66-5324-486f-f319-7451c87b0a90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Reconhecimento de Entidades:\n",
            "     Entidade    Tipo\n",
            "0       Apple     ORG\n",
            "1        U.K.     GPE\n",
            "2  $1 billion   MONEY\n",
            "3  Steve Jobs  PERSON\n",
            "4        1976    DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Análise Semântica com WordNet\n",
        "semantic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  synsets = wn.synsets(token.text)\n",
        "  if synsets:\n",
        "    semantic_data.append({\n",
        "        \"Palavra\": token.text,\n",
        "        \"Significado\": synsets[0].definition(),\n",
        "        \"Exemplo\": synsets[0].examples()\n",
        "    })\n",
        "\n",
        "# Convertendo para DataFrame\n",
        "df_semantic = pd.DataFrame(semantic_data)\n",
        "print(\"\\n Análise Semântica:\")\n",
        "print(df_semantic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n1E0USZITqr",
        "outputId": "ca8a7d94-2a40-4e47-d37d-50e8b7449eed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Análise Semântica:\n",
            "    Palavra                                        Significado  \\\n",
            "0     Apple  fruit with red or yellow or green skin and swe...   \n",
            "1        is  have the quality of being; (copula, used with ...   \n",
            "2   looking  the act of directing the eyes toward something...   \n",
            "3        at  a highly unstable radioactive element (the hea...   \n",
            "4    buying                                  the act of buying   \n",
            "5      U.K.  a monarchy in northwestern Europe occupying mo...   \n",
            "6   startup                    the act of setting in operation   \n",
            "7         1  the smallest whole number or a numeral represe...   \n",
            "8   billion  the number that is represented as a one follow...   \n",
            "9      Jobs  the principal activity in your life that you d...   \n",
            "10  founded                                    set up or found   \n",
            "11    apple  fruit with red or yellow or green skin and swe...   \n",
            "12       in    a unit of length equal to one twelfth of a foot   \n",
            "\n",
            "                                              Exemplo  \n",
            "0                                                  []  \n",
            "1           [John is rich, This is not a good answer]  \n",
            "2   [he went out to have a look, his look was fixe...  \n",
            "3                                                  []  \n",
            "4   [buying and selling fill their days, shrewd pu...  \n",
            "5                                                  []  \n",
            "6     [repeated shutdowns and startups are expensive]  \n",
            "7   [he has the one but will need a two and three ...  \n",
            "8                                                  []  \n",
            "9                   [he's not in my line of business]  \n",
            "10                    [She set up a literacy program]  \n",
            "11                                                 []  \n",
            "12                                                 []  \n"
          ]
        }
      ]
    }
  ]
}